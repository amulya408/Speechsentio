{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8139582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "Root = \"C:\\\\Users\\\\BEHARA AMULYA\\\\Downloads\\\\speech emotion\"\n",
    "os.chdir(Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c206f9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is E8BE-5ED1\n",
      "\n",
      " Directory of C:\\Users\\BEHARA AMULYA\\Downloads\\speech emotion\n",
      "\n",
      "15-02-2024  12:29    <DIR>          .\n",
      "15-02-2024  12:45    <DIR>          ..\n",
      "25-01-2024  14:20    <DIR>          .ipynb_checkpoints\n",
      "25-01-2024  14:18         1,338,199 modelForPrediction1.sav\n",
      "15-02-2024  12:29            21,861 Speech Emotion Recognition.ipynb\n",
      "25-01-2024  12:41    <DIR>          speech-emotion-recognition-ravdess-data\n",
      "               2 File(s)      1,360,060 bytes\n",
      "               4 Dir(s)  24,520,441,856 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd2e278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (0.55.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (1.9.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (1.21.5)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.38.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.5.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (21.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from packaging>=20.0->pooch>=1.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\behara amulya\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49221dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62638138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ffd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "#Emotions to observe\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d53f072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(r\"C:\\Users\\BEHARA AMULYA\\Downloads\\speech emotion\\speech-emotion-recognition-ravdess-data\\Actor_*\\*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf20c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e182df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.22061890e+02,  3.50668907e+01,  3.75342965e+00, ...,\n",
       "         1.65243153e-04,  1.04321596e-04,  6.55571566e-05],\n",
       "       [-6.41227722e+02,  4.49487762e+01, -1.85174119e+00, ...,\n",
       "         3.89261913e-05,  3.05255380e-05,  2.94166657e-05],\n",
       "       [-6.50705750e+02,  5.30211639e+01, -4.92040443e+00, ...,\n",
       "         4.75216802e-05,  3.46632514e-05,  1.62844426e-05],\n",
       "       ...,\n",
       "       [-5.50096191e+02,  1.70297680e+01, -1.14575634e+01, ...,\n",
       "         1.51764631e-04,  1.16828531e-04,  8.47479314e-05],\n",
       "       [-5.55357605e+02,  4.71569710e+01,  1.10750742e+01, ...,\n",
       "         1.61086457e-04,  1.04962470e-04,  6.52811723e-05],\n",
       "       [-5.04816345e+02,  3.53618660e+01, -1.43495789e+01, ...,\n",
       "         6.08151488e-04,  5.55269769e-04,  4.47782222e-04]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4214c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 192)\n"
     ]
    }
   ],
   "source": [
    "#Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d988484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "#Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f82d84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fc4a29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8128e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict for the test set\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc0b404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'calm', 'happy', 'happy', 'disgust', 'calm', 'disgust',\n",
       "       'happy', 'calm', 'happy', 'happy', 'calm', 'fearful', 'happy',\n",
       "       'disgust', 'happy', 'calm', 'disgust', 'happy', 'calm', 'calm',\n",
       "       'disgust', 'disgust', 'calm', 'happy', 'happy', 'calm', 'happy',\n",
       "       'fearful', 'happy', 'happy', 'fearful', 'happy', 'fearful',\n",
       "       'happy', 'calm', 'calm', 'fearful', 'calm', 'disgust', 'happy',\n",
       "       'calm', 'calm', 'calm', 'fearful', 'calm', 'disgust', 'happy',\n",
       "       'calm', 'happy', 'fearful', 'fearful', 'calm', 'happy', 'happy',\n",
       "       'happy', 'disgust', 'happy', 'calm', 'calm', 'disgust', 'calm',\n",
       "       'happy', 'calm', 'happy', 'calm', 'calm', 'disgust', 'fearful',\n",
       "       'happy', 'fearful', 'fearful', 'fearful', 'fearful', 'fearful',\n",
       "       'disgust', 'fearful', 'happy', 'calm', 'fearful', 'disgust',\n",
       "       'calm', 'fearful', 'calm', 'disgust', 'happy', 'disgust', 'happy',\n",
       "       'happy', 'fearful', 'disgust', 'calm', 'calm', 'happy', 'disgust',\n",
       "       'happy', 'calm', 'calm', 'calm', 'happy', 'fearful', 'happy',\n",
       "       'disgust', 'happy', 'fearful', 'calm', 'disgust', 'happy',\n",
       "       'fearful', 'happy', 'happy', 'calm', 'calm', 'fearful', 'fearful',\n",
       "       'calm', 'calm', 'happy', 'calm', 'fearful', 'calm', 'happy',\n",
       "       'calm', 'happy', 'fearful', 'calm', 'disgust', 'happy', 'calm',\n",
       "       'calm', 'fearful', 'happy', 'happy', 'disgust', 'disgust',\n",
       "       'disgust', 'fearful', 'happy', 'happy', 'disgust', 'calm',\n",
       "       'fearful', 'happy', 'disgust', 'happy', 'fearful', 'disgust',\n",
       "       'happy', 'happy', 'calm', 'calm', 'happy', 'happy', 'calm',\n",
       "       'happy', 'calm', 'calm', 'fearful', 'calm', 'happy', 'disgust',\n",
       "       'calm', 'happy', 'calm', 'calm', 'happy', 'fearful', 'happy',\n",
       "       'calm', 'happy', 'happy', 'fearful', 'happy', 'disgust', 'happy',\n",
       "       'fearful', 'calm', 'fearful', 'calm', 'happy', 'disgust',\n",
       "       'fearful', 'calm', 'calm', 'disgust', 'fearful', 'happy',\n",
       "       'fearful', 'happy', 'happy', 'disgust', 'calm'], dtype='<U7')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4af41aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.88%\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "#Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "683aa447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b330236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86206897, 0.60759494, 0.67567568, 0.67826087])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84ff57d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>happy</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>disgust</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>disgust</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>happy</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>disgust</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fearful</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>happy</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>disgust</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>disgust</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Predicted\n",
       "0     happy     happy\n",
       "1      calm      calm\n",
       "2     happy     happy\n",
       "3     happy     happy\n",
       "4   disgust   disgust\n",
       "5      calm      calm\n",
       "6     happy   disgust\n",
       "7     happy     happy\n",
       "8   disgust      calm\n",
       "9     happy     happy\n",
       "10    happy     happy\n",
       "11  disgust      calm\n",
       "12    happy   fearful\n",
       "13    happy     happy\n",
       "14  disgust   disgust\n",
       "15  fearful     happy\n",
       "16     calm      calm\n",
       "17    happy   disgust\n",
       "18  disgust     happy\n",
       "19  disgust      calm"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Actual': y_test, 'Predicted':y_pred})\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8659825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Writing different model files to file\n",
    "with open( 'modelForPrediction1.sav', 'wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "907f7e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy'], dtype='<U7')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'modelForPrediction1.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb')) # loading the model file from the storage\n",
    "\n",
    "feature=extract_feature(r\"C:\\Users\\BEHARA AMULYA\\Downloads\\speech emotion\\speech-emotion-recognition-ravdess-data/Actor_01/03-01-01-01-01-01-01.wav\", mfcc=True, chroma=True, mel=True)\n",
    "\n",
    "feature=feature.reshape(1,-1)\n",
    "\n",
    "prediction=loaded_model.predict(feature)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b931e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
